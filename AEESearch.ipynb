{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IgsjwKiJlLiA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtOvuE_HlN7S"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MNZNJU5VlPkQ"
      },
      "outputs": [],
      "source": [
        "def CreateEncoder(Shape):\n",
        "    Inputs = Input(shape=Shape)\n",
        "\n",
        "    #PTEncoder = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', pooling='avg') #pre_trained_encoder.trainable = False\n",
        "    PTEncoder = tf.keras.applications.VGG16(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "    # Connect the encoder with the inputs\n",
        "    x = PTEncoder(Inputs)\n",
        "\n",
        "    # Define additional layers\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "\n",
        "    # Define model\n",
        "    encoder = Model(inputs=Inputs, outputs=x)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h249uCchlQen"
      },
      "outputs": [],
      "source": [
        "def CreateDecoder(Shape):\n",
        "    Inputs = Input(Shape)\n",
        "\n",
        "    # Define dense layers\n",
        "    x = Dense(512, activation='relu')(Inputs)\n",
        "    x = Dense(7 * 7 * 128, activation='relu')(x)\n",
        "\n",
        "    # Reshape the dense output to match the shape of the last convolutional layer in the encoder\n",
        "    x = tf.reshape(x, (-1, 7, 7, 128))\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Define model\n",
        "    decoder = Model(inputs=Inputs, outputs=x)\n",
        "\n",
        "    return decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jDep-xUglTJ8"
      },
      "outputs": [],
      "source": [
        "def CreateAutoencoder(encoder, decoder, Shape):\n",
        "    Inputs = Input(shape=Shape)\n",
        "\n",
        "    # Encode the input image\n",
        "    encoded = encoder(Inputs)\n",
        "\n",
        "    # Decode the encoded representation\n",
        "    decoded = decoder(encoded)\n",
        "\n",
        "    # Define autoencoder model\n",
        "    Autoencoder = Model(inputs=Inputs, outputs=decoded)\n",
        "\n",
        "    return Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iNK_kGMOlXOg"
      },
      "outputs": [],
      "source": [
        "def CreatePath(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QgGTjWhClZd8"
      },
      "outputs": [],
      "source": [
        "def SaveImage(ImagePath, ImageName, NImagesPath):\n",
        "    InputImage = Image.open(ImagePath)\n",
        "    InputImagePath = os.path.join(NImagesPath, ImageName + '.jpg')\n",
        "    InputImage.save(InputImagePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tjN8a7JxlbJi"
      },
      "outputs": [],
      "source": [
        "def CreateFigure(ImagePath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=len(SimilarImages) + 1, figsize=(15, 5))\n",
        "\n",
        "    InputImage = Image.open(ImagePath)\n",
        "    ax[0].imshow(InputImage)\n",
        "    #ax[0].set_title(f'Input Image\\n{TotalPercentageSimilarity:.2f}%')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    for i, img in enumerate(SimilarImages):\n",
        "        img = Image.open(img)\n",
        "        img = img.resize(InputImage.size)\n",
        "        ax[i+1].set_title(f'{SimilarityPercentages[i]:.2f}%')\n",
        "        #ax[i+1].set_title(f'{distances[i]:.2f}')\n",
        "        ax[i+1].imshow(img)\n",
        "        ax[i+1].axis('off')\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9NvvdR0Elcl8"
      },
      "outputs": [],
      "source": [
        "def ShowSimilarImages(ImagePath, SimilarImagesPath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances):\n",
        "  \n",
        "    if not SimilarImages:\n",
        "        print('No similar images found.')\n",
        "    else:\n",
        "        CreatePath(SimilarImagesPath)\n",
        "        SaveImage(ImagePath, 'InputImage', SimilarImagesPath)\n",
        "\n",
        "        for i, p in enumerate(SimilarImages):\n",
        "            #SaveImage(p, f'SimilarImage{i+1}_{SimilarityPercentages[i]:.2f}', SimilarImagesPath)\n",
        "            SaveImage(p, f'SimilarImage{i+1}_{distances[i]:.2f}', SimilarImagesPath)\n",
        "\n",
        "        fig = CreateFigure(ImagePath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "r179-GE1ldxP"
      },
      "outputs": [],
      "source": [
        "def Preprocess(img, Shape):\n",
        "    img = img.resize(Shape)\n",
        "    img = img.convert('RGB')\n",
        "    img = np.array(img) / 255.0\n",
        "    \n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "   \n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2pQAUUtOlftz"
      },
      "outputs": [],
      "source": [
        "def LoadDataset(path, Shape):\n",
        "    Images = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for dir in dirs:\n",
        "            for file in os.listdir(os.path.join(root, dir)):\n",
        "\n",
        "                if file.endswith('.jpg') or file.endswith('.png'):\n",
        "\n",
        "                    img = Image.open(os.path.join(root, dir, file))\n",
        "\n",
        "                    if img is not None:\n",
        "                        img = tf.keras.preprocessing.image.array_to_img(img)\n",
        "                        img = Preprocess(img, Shape)\n",
        "                        Images.append(img)\n",
        "    \n",
        "    if Images:\n",
        "        Images = np.concatenate(Images)\n",
        "\n",
        "    return Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kGLS5PaHlhmp"
      },
      "outputs": [],
      "source": [
        "def TrainAutoencoder(Encoder, Autoencoder, Images, batch_size, epochs):\n",
        "    # Compile the autoencoder\n",
        "    Autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the autoencoder\n",
        "    Autoencoder.fit(Images, Images, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "    return Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "r31sRJ3jljNf"
      },
      "outputs": [],
      "source": [
        "def LoadModel(DataPath, ModelPath, Shape, Encoder, Autoencoder, batch_size, epochs):\n",
        "    if os.path.exists(ModelPath):\n",
        "        Autoencoder = tf.keras.models.load_model(ModelPath)\n",
        "            \n",
        "    else:\n",
        "        Images = LoadDataset(DataPath, Shape)\n",
        "        Autoencoder = TrainAutoencoder(Encoder, Autoencoder, Images, batch_size, epochs)\n",
        "        \n",
        "        Autoencoder.save(ModelPath)\n",
        "        \n",
        "    return Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hlrBck0WwtqS"
      },
      "outputs": [],
      "source": [
        "def EuclideanDistance(img1, img2):\n",
        "  SquaredDifference = np.square(img1 - img2)\n",
        "  SummedSquaredDifference = np.sum(SquaredDifference)\n",
        "  Distance = np.sqrt(SummedSquaredDifference)\n",
        "\n",
        "  return Distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "b7Q0Me_3ll-a"
      },
      "outputs": [],
      "source": [
        "def Search(path, ImagePath, Shape, Encoder, n_neighbors):\n",
        "    img = Image.open(ImagePath)\n",
        "    img = Preprocess(img, Shape)\n",
        "    \n",
        "    img_embedding = Encoder.predict(img)\n",
        "\n",
        "    SimilarImages = []\n",
        "    SimilarityPercentages = []\n",
        "    distances = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "      for dir in dirs:\n",
        "        FilePath = os.path.join(root, dir)\n",
        "        FileList = os.listdir(FilePath)\n",
        "\n",
        "        if not FileList:\n",
        "          print('Error: No files found in directory.', FilePath)\n",
        "          continue\n",
        "\n",
        "        for File in FileList:\n",
        "            SimilarImages.append(os.path.join(FilePath, File))\n",
        "\n",
        "            img2 = Image.open(os.path.join(FilePath, File))\n",
        "            img2 = Preprocess(img2, Shape)\n",
        "            img2_embedding = Encoder.predict(img2)\n",
        "\n",
        "            distance = EuclideanDistance(img_embedding, img2_embedding)\n",
        "            distances.append(distance)\n",
        "\n",
        "            #SimilarityPercentage = (1 - distance) * 100\n",
        "            #SimilarityPercentages.append(SimilarityPercentage)\n",
        "\n",
        "    MDistance = np.max(distances)\n",
        "\n",
        "    SortedSimilarity = sorted(zip(distances, SimilarImages), reverse=False) #SortedSimilarity = sorted(zip(SimilarityPercentages, SimilarImages), reverse=True)\n",
        "    distances, SimilarImages = zip(*SortedSimilarity) #SimilarityPercentages, SimilarImages = zip(*SortedSimilarity)\n",
        "\n",
        "    SimilarImages = list(SimilarImages)[:n_neighbors]\n",
        "    distances = list(distances)[:n_neighbors] #SimilarityPercentages = list(SimilarityPercentages)[:n_neighbors]\n",
        "\n",
        "    SimilarityPercentages = [(1 - distance / MDistance) * 100 for distance in distances]\n",
        "    #SimilarityPercentages = [round((1 - distance) * 100, 2) for distance in distances[0]]\n",
        "    \n",
        "    TotalPercentageSimilarity = np.round(np.sum(SimilarityPercentages) / len(SimilarityPercentages), 2)\n",
        "    #TotalPercentageSimilarity = round(sum([(1 - distance) for distance in distances[0]]) * 100 / len(distances[0]), 2)\n",
        "    #TotalPercentageSimilarity = sum(SimilarityPercentages) / len(SimilarityPercentages)\n",
        "    \n",
        "    return SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "akR3ToqalGM0"
      },
      "outputs": [],
      "source": [
        "cwd = os.getcwd()\n",
        "DataPath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'Images')\n",
        "ModelPath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'SavedModel', 'Model.h5')\n",
        "SimilarImagesPath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'SavedModel', 'SimilarImages')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "3TuC9QdMlpCJ"
      },
      "outputs": [],
      "source": [
        "image_width = 56\n",
        "image_height = 56\n",
        "\n",
        "Shape = (image_width, image_height, 3)\n",
        "SPreprocess = (image_width, image_height)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "n_neighbors = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZQLQxi0Ylu5Y"
      },
      "outputs": [],
      "source": [
        "Encoder = CreateEncoder(Shape)\n",
        "Decoder = CreateDecoder(Encoder.layers[-1].output_shape[1:])\n",
        "Autoencoder = CreateAutoencoder(Encoder, Decoder, Shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Autoencoder = LoadModel(DataPath, ModelPath, SPreprocess, Encoder, Autoencoder, batch_size, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtQ2XNNIlxyr"
      },
      "outputs": [],
      "source": [
        "ImagePath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'Dog.jpg')\n",
        "\n",
        "SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances = Search(DataPath, ImagePath, SPreprocess, Encoder, n_neighbors)\n",
        "\n",
        "ShowSimilarImages(ImagePath, SimilarImagesPath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
