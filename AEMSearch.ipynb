{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VBi50EWztLV_"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from sklearn.neighbors import KDTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ykHhidfotNJY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EO8Jvt_atPIy"
      },
      "outputs": [],
      "source": [
        "def CreateEncoder(Shape):\n",
        "    Inputs = Input(shape=Shape)\n",
        "\n",
        "    #PTEncoder = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', pooling='avg') #pre_trained_encoder.trainable = False\n",
        "    PTEncoder = tf.keras.applications.VGG16(include_top=False, weights='imagenet', pooling='avg')\n",
        "\n",
        "    # Connect the encoder with the inputs\n",
        "    x = PTEncoder(Inputs)\n",
        "\n",
        "    # Define additional layers\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "\n",
        "    # Define model\n",
        "    encoder = Model(inputs=Inputs, outputs=x)\n",
        "\n",
        "    return encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M7ZckNFztQtW"
      },
      "outputs": [],
      "source": [
        "def CreateDecoder(Shape):\n",
        "    Inputs = Input(Shape)\n",
        "\n",
        "    # Define dense layers\n",
        "    x = Dense(512, activation='relu')(Inputs)\n",
        "    x = Dense(7 * 7 * 128, activation='relu')(x)\n",
        "\n",
        "    # Reshape the dense output to match the shape of the last convolutional layer in the encoder\n",
        "    x = tf.reshape(x, (-1, 7, 7, 128))\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
        "    x = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Define model\n",
        "    decoder = Model(inputs=Inputs, outputs=x)\n",
        "\n",
        "    return decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IcZoudevtSWt"
      },
      "outputs": [],
      "source": [
        "def CreateAutoencoder(encoder, decoder, Shape):\n",
        "    Inputs = Input(shape=Shape)\n",
        "\n",
        "    # Encode the input image\n",
        "    encoded = encoder(Inputs)\n",
        "\n",
        "    # Decode the encoded representation\n",
        "    decoded = decoder(encoded)\n",
        "\n",
        "    # Define autoencoder model\n",
        "    Autoencoder = Model(inputs=Inputs, outputs=decoded)\n",
        "\n",
        "    return Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j30inrbYeufU"
      },
      "outputs": [],
      "source": [
        "def CreatePath(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_44SdDqYeufV"
      },
      "outputs": [],
      "source": [
        "def SaveImage(ImagePath, ImageName, NImagesPath):\n",
        "    InputImage = Image.open(ImagePath)\n",
        "    InputImagePath = os.path.join(NImagesPath, ImageName + '.jpg')\n",
        "    InputImage.save(InputImagePath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "bU0VfLM6tmdo"
      },
      "outputs": [],
      "source": [
        "def CreateFigure(ImagePath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances):\n",
        "    fig, ax = plt.subplots(nrows=1, ncols=len(SimilarImages) + 1, figsize=(15, 5))\n",
        "\n",
        "    InputImage = Image.open(ImagePath)\n",
        "    ax[0].imshow(InputImage)\n",
        "    #ax[0].set_title(f'Input Image\\n{TotalPercentageSimilarity:.2f}%')\n",
        "    ax[0].axis('off')\n",
        "\n",
        "    for i, img in enumerate(SimilarImages):\n",
        "        img = Image.open(img)\n",
        "        img = img.resize(InputImage.size)\n",
        "        ax[i+1].set_title(f'{SimilarityPercentages[i]:.2f}%')\n",
        "        #ax[i+1].set_title(f'{distances[i]:.2f}')\n",
        "        ax[i+1].imshow(img)\n",
        "        ax[i+1].axis('off')\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fZyvwl7TsNvN"
      },
      "outputs": [],
      "source": [
        "def ShowSimilarImages(ImagePath, SimilarImagesPath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances):\n",
        "  \n",
        "    if not SimilarImages:\n",
        "        print('No similar images found.')\n",
        "    else:\n",
        "        CreatePath(SimilarImagesPath)\n",
        "        SaveImage(ImagePath, 'InputImage', SimilarImagesPath)\n",
        "\n",
        "        for i, p in enumerate(SimilarImages):\n",
        "            #SaveImage(p, f'SimilarImage{i+1}_{SimilarityPercentages[i]:.2f}', SimilarImagesPath)\n",
        "            SaveImage(p, f'SimilarImage{i+1}_{distances[i]:.2f}', SimilarImagesPath)\n",
        "\n",
        "        fig = CreateFigure(ImagePath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_3AxVh2qtUdy"
      },
      "outputs": [],
      "source": [
        "def Preprocess(img, Shape):\n",
        "    img = img.resize(Shape)\n",
        "    img = img.convert('RGB')\n",
        "    img = np.array(img) / 255.0\n",
        "    \n",
        "    img = tf.expand_dims(img, axis=0)\n",
        "   \n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o5g-InjUtWbX"
      },
      "outputs": [],
      "source": [
        "def LoadDataset(path, Shape):\n",
        "    Images = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for dir in dirs:\n",
        "            for file in os.listdir(os.path.join(root, dir)):\n",
        "\n",
        "                if file.endswith('.jpg') or file.endswith('.png'):\n",
        "\n",
        "                    img = Image.open(os.path.join(root, dir, file))\n",
        "\n",
        "                    if img is not None:\n",
        "                        img = tf.keras.preprocessing.image.array_to_img(img)\n",
        "                        img = Preprocess(img, Shape)\n",
        "                        Images.append(img)\n",
        "    \n",
        "    if Images:\n",
        "        Images = np.concatenate(Images)\n",
        "\n",
        "    return Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-CoPbolMtZJK"
      },
      "outputs": [],
      "source": [
        "def TrainAutoencoder(Encoder, Autoencoder, Images, batch_size, epochs):\n",
        "    # Compile the autoencoder\n",
        "    Autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    # Train the autoencoder\n",
        "    Autoencoder.fit(Images, Images, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "    Tree = KDTree(Encoder.predict(Images), metric='manhattan') ## Using Manhattan distance\n",
        "\n",
        "    return Autoencoder, Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "71GUAN3xeufa"
      },
      "outputs": [],
      "source": [
        "def LoadModel(DataPath, ModelPath, TreePath, Shape, Encoder, Autoencoder, batch_size, epochs):\n",
        "    if os.path.exists(ModelPath):\n",
        "        Autoencoder = tf.keras.models.load_model(ModelPath)\n",
        "\n",
        "        if os.path.exists(TreePath):\n",
        "          with open(TreePath, 'rb') as f:\n",
        "            Tree = pickle.load(f)\n",
        "            \n",
        "    else:\n",
        "        Images = LoadDataset(DataPath, Shape)\n",
        "        Autoencoder, Tree = TrainAutoencoder(Encoder, Autoencoder, Images, batch_size, epochs)\n",
        "        \n",
        "        Autoencoder.save(ModelPath)\n",
        "        with open(TreePath, 'wb') as f:\n",
        "            pickle.dump(Tree, f)\n",
        "        \n",
        "    return Autoencoder, Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0OGWI93BtkIw"
      },
      "outputs": [],
      "source": [
        "def Search(path, ImagePath, Tree, Shape, Encoder, n_neighbors):\n",
        "    img = Image.open(ImagePath)\n",
        "    img = Preprocess(img, Shape)\n",
        "    \n",
        "    img_embedding = Encoder.predict(img)\n",
        "\n",
        "    distances, indices = Tree.query(img_embedding, k=n_neighbors)\n",
        "\n",
        "    SimilarImages = []\n",
        "    SimilarityPercentages = []\n",
        "\n",
        "    for root, dirs, files in os.walk(path):\n",
        "      for dir in dirs:\n",
        "        FilePath = os.path.join(root, dir)\n",
        "        FileList = os.listdir(FilePath)\n",
        "\n",
        "        if not FileList:\n",
        "          print('Error: No files found in directory.', FilePath)\n",
        "          continue\n",
        "\n",
        "        for idx in indices[0]:\n",
        "            SimilarImages.append(os.path.join(FilePath, FileList[idx]))\n",
        "\n",
        "    MDistance = np.max(distances)\n",
        "    SimilarityPercentages = [(1 - distance / MDistance) * 100 for distance in distances]\n",
        "    #SimilarityPercentages = [round((1 - distance) * 100, 2) for distance in distances[0]]\n",
        "    \n",
        "    TotalPercentageSimilarity = np.round(np.sum(SimilarityPercentages) / len(SimilarityPercentages), 2)\n",
        "    #TotalPercentageSimilarity = round(sum([(1 - distance) for distance in distances[0]]) * 100 / len(distances[0]), 2)\n",
        "    \n",
        "    distances = distances.tolist()\n",
        "    distances = distances[0]\n",
        "\n",
        "    SimilarityPercentages = SimilarityPercentages[0]\n",
        "\n",
        "    return SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XFhGgOCptpwP"
      },
      "outputs": [],
      "source": [
        "cwd = os.getcwd()\n",
        "DataPath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'Images')\n",
        "ModelPath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'SavedModel', 'Model.h5')\n",
        "SimilarImagesPath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'SavedModel', 'SimilarImages')\n",
        "TreePath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'archive', 'SavedModel', 'Tree.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "p3fko_v2tsEb"
      },
      "outputs": [],
      "source": [
        "image_width = 56\n",
        "image_height = 56\n",
        "\n",
        "Shape = (image_width, image_height, 3)\n",
        "SPreprocess = (image_width, image_height)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "\n",
        "n_neighbors = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m8JI8G8Neufc"
      },
      "outputs": [],
      "source": [
        "Encoder = CreateEncoder(Shape)\n",
        "Decoder = CreateDecoder(Encoder.layers[-1].output_shape[1:])\n",
        "Autoencoder = CreateAutoencoder(Encoder, Decoder, Shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72zuGnRGtuwI"
      },
      "outputs": [],
      "source": [
        "Autoencoder, Tree = LoadModel(DataPath, ModelPath, TreePath, SPreprocess, Encoder, Autoencoder, batch_size, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9e2TfMFntxDm"
      },
      "outputs": [],
      "source": [
        "ImagePath = os.path.join(cwd, 'drive', 'MyDrive', 'Colab Notebooks', 'Dog.jpg')\n",
        "\n",
        "SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances = Search(DataPath, ImagePath, Tree, SPreprocess, Encoder, n_neighbors)\n",
        "\n",
        "ShowSimilarImages(ImagePath, SimilarImagesPath, SimilarImages, SimilarityPercentages, TotalPercentageSimilarity, distances)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
